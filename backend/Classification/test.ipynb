{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            self._block(1, 32, 3),\n",
    "            self._block(32, 48, 3, 2),\n",
    "            self._block(48, 64, 3),\n",
    "            self._block(64, 80, 3),\n",
    "            self._block(80, 96, 3, 2),\n",
    "            self._block(96, 112, 3),\n",
    "            self._block(112, 128, 3),\n",
    "            self._block(128, 144, 3, 2),\n",
    "            self._block(144, 154, 3),\n",
    "            self._block(154, 116, 3),\n",
    "            Flatten(),\n",
    "            nn.Linear(16704, 2, bias=False),\n",
    "            nn.BatchNorm1d(2), \n",
    "        ) \n",
    "\n",
    "    def _block(self, input_dim, output_dim, kernel_size, stride=1):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(input_dim, output_dim, kernel_size, stride, bias=False),\n",
    "            nn.BatchNorm2d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x.permute(0, 2, 3, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tictactoeTransform = A.Compose([\n",
    "    A.RandomCrop(162, 162, p=0.4),\n",
    "    A.InvertImg(p=0.18),\n",
    "    A.ColorJitter(brightness=0.55, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "    A.GaussNoise(p=0.28),\n",
    "    A.Blur(blur_limit=4, p=0.22),\n",
    "    A.GlassBlur(max_delta=1, iterations=1, p=0.14),\n",
    "    A.CLAHE(p=0.3),\n",
    "    A.Sharpen(p=0.2),\n",
    "    A.Emboss(p=0.18),\n",
    "    A.Equalize(p=0.05),\n",
    "    A.MultiplicativeNoise(p=0.22),\n",
    "    A.Resize(168, 168, p=1.0, interpolation=Image.NEAREST),\n",
    "])\n",
    "\n",
    "connectfourTransform = A.Compose([\n",
    "    A.RandomCrop(152, 152, p=0.4),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.ColorJitter(brightness=0.55, contrast=0.6, saturation=0.6, hue=0.6, p=0.4),\n",
    "    A.GaussNoise(p=0.12),\n",
    "    A.Blur(blur_limit=4, p=0.22),\n",
    "    A.GlassBlur(max_delta=1, iterations=1, p=0.14),\n",
    "    A.CLAHE(p=0.3),\n",
    "    A.Sharpen(p=0.2),\n",
    "    A.Emboss(p=0.18),\n",
    "    A.Equalize(p=0.05),\n",
    "    A.MultiplicativeNoise(p=0.22),\n",
    "    A.Resize(168, 168, p=1.0, interpolation=Image.NEAREST),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.load_state_dict(torch.load('/home/robert/Documents/GitHub/OutSmarted/backend/Classification/classificaton.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgPath = '../TicTacToe/data/boards/raw/1.jpg'\n",
    "imgPath = '../ConnectFour/data/boards/1.jpg'\n",
    "imgPath = '1.jpg'\n",
    "img = Image.open(imgPath)\n",
    "img = img.resize((168, 168))\n",
    "img = img.convert('L')\n",
    "img = np.array(img)\n",
    "# img = connectfourTransform(image=img)['image']\n",
    "plt.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(model(to_tensor(img).reshape(1, 1, 168, 168)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2177f1ca12c1330a133c1d40b46100b268ab447cddcbdfdc0c7b2b7e4840e700"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
