{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from torchvision.transforms.functional import to_tensor\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FieldModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            self._block(1, 32, 3),\n",
    "            self._block(32, 48, 3),\n",
    "            self._block(48, 64, 3),\n",
    "            self._block(64, 80, 3),\n",
    "            self._block(80, 96, 3),\n",
    "            self._block(96, 112, 3),\n",
    "            self._block(112, 128, 3),\n",
    "            self._block(128, 144, 3),\n",
    "            self._block(144, 160, 3),\n",
    "            self._block(160, 176, 3),\n",
    "            Flatten(),\n",
    "            nn.Linear(11264, 3, bias=False),\n",
    "            nn.BatchNorm1d(3),\n",
    "        )\n",
    "\n",
    "    def _block(self, input_dim, output_dim, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(input_dim, output_dim, kernel_size, bias=False),\n",
    "            nn.BatchNorm2d(output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return torch.flatten(x.permute(0, 2, 3, 1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (28, 3, 1),\n",
    "    (64, 3, 2),\n",
    "    [\"B\", 1],\n",
    "    (124, 3, 2),\n",
    "    [\"B\", 2],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 6],\n",
    "    (256, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 2),\n",
    "    [\"B\", 8],\n",
    "    (512, 3, 1),\n",
    "    [\"B\", 4],\n",
    "    (256, 2, 1),\n",
    "    (96, 3, 1),\n",
    "    (19, 3, 1),\n",
    "]\n",
    "\n",
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bn_act=True, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=not bn_act, **kwargs)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.1)\n",
    "        self.use_bn_act = bn_act\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn_act:\n",
    "            return self.leaky(self.bn(self.conv(x)))\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, use_residual=True, num_repeats=1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for repeat in range(num_repeats):\n",
    "            self.layers += [\n",
    "                nn.Sequential(\n",
    "                    CNNBlock(channels, channels // 2, kernel_size=1),\n",
    "                    CNNBlock(channels // 2, channels, kernel_size=3, padding=1),\n",
    "                )\n",
    "            ]\n",
    "        self.use_residual = use_residual\n",
    "        self.num_repeats = num_repeats\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            if self.use_residual:\n",
    "                x = x + layer(x)\n",
    "            else:\n",
    "                x = layer(x)\n",
    "        return x\n",
    "\n",
    "class BoardModel(nn.Module):\n",
    "    def __init__(self, in_channels=1):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.layers = self._create_conv_layers()\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "          x = layer(x)\n",
    "        return torch.flatten(x, start_dim=1)\n",
    "\n",
    "    def _create_conv_layers(self):\n",
    "        layers = nn.ModuleList()\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for idx, module in enumerate(config):\n",
    "            if isinstance(module, tuple):\n",
    "                out_channels, kernel_size, stride = module\n",
    "                layers.append(\n",
    "                    CNNBlock(\n",
    "                        in_channels,\n",
    "                        out_channels,\n",
    "                        kernel_size=kernel_size,\n",
    "                        stride=stride,\n",
    "                        padding=1 if kernel_size >= 2 else 0,\n",
    "                    )\n",
    "                )\n",
    "                in_channels = out_channels\n",
    "\n",
    "            elif isinstance(module, list):\n",
    "                num_repeats = module[1]\n",
    "                layers.append(ResidualBlock(in_channels, num_repeats=num_repeats,))\n",
    "        return layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    if box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]  # (N, 1)\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n",
    "\n",
    "def non_max_suppression(bboxes, iou_threshold, threshold, box_format=\"corners\"):\n",
    "    assert type(bboxes) == list\n",
    "    bboxes = [box for box in bboxes if box[1] > threshold]\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[1], reverse=True)\n",
    "    bboxes_after_nms = []\n",
    "\n",
    "    while bboxes:\n",
    "        chosen_box = bboxes.pop(0)\n",
    "        bboxes = [\n",
    "            box\n",
    "            for box in bboxes\n",
    "            if box[0] != chosen_box[0]\n",
    "            or intersection_over_union(\n",
    "                torch.tensor(chosen_box[2:]),\n",
    "                torch.tensor(box[2:]),\n",
    "                box_format=box_format,\n",
    "            )\n",
    "            < iou_threshold\n",
    "        ]\n",
    "        bboxes_after_nms.append(chosen_box)\n",
    "    return bboxes_after_nms\n",
    "\n",
    "def convert_cellboxes(predictions, S=7, C=9):\n",
    "    predictions = predictions.to(\"cpu\")\n",
    "    batch_size = predictions.shape[0]\n",
    "    predictions = predictions.reshape(batch_size, 7, 7, C+10)\n",
    "    bboxes1 = predictions[..., C+1:C+5]\n",
    "    bboxes2 = predictions[..., C+6:C+10]\n",
    "    scores = torch.cat(\n",
    "        (predictions[..., C].unsqueeze(0), predictions[..., C+5].unsqueeze(0)), dim=0\n",
    "    )\n",
    "    best_box = scores.argmax(0).unsqueeze(-1)\n",
    "    best_boxes = bboxes1 * (1 - best_box) + best_box * bboxes2\n",
    "    cell_indices = torch.arange(S).repeat(batch_size, S, 1).unsqueeze(-1)\n",
    "    x = 1 / S * (best_boxes[..., :1] + cell_indices)\n",
    "    y = 1 / S * (best_boxes[..., 1:2] + cell_indices.permute(0, 2, 1, 3))\n",
    "    w_y = 1 / S * best_boxes[..., 2:4]\n",
    "    converted_bboxes = torch.cat((x, y, w_y), dim=-1)\n",
    "    predicted_class = predictions[..., :C].argmax(-1).unsqueeze(-1)\n",
    "    best_confidence = torch.max(predictions[..., C], predictions[..., C+5]).unsqueeze(\n",
    "        -1\n",
    "    )\n",
    "    converted_preds = torch.cat(\n",
    "        (predicted_class, best_confidence, converted_bboxes), dim=-1\n",
    "    )\n",
    "    return converted_preds\n",
    "    \n",
    "def cellboxes_to_boxes(out, S=7, C=9):\n",
    "    converted_pred = convert_cellboxes(out).reshape(out.shape[0], S * S, -1)\n",
    "    converted_pred[..., 0] = converted_pred[..., 0].long()\n",
    "    all_bboxes = []\n",
    "\n",
    "    for ex_idx in range(out.shape[0]):\n",
    "        bboxes = []\n",
    "\n",
    "        for bbox_idx in range(S * S):\n",
    "            bboxes.append([x.item() for x in converted_pred[ex_idx, bbox_idx, :]])\n",
    "        all_bboxes.append(bboxes)\n",
    "\n",
    "    return all_bboxes\n",
    "\n",
    "def plot_image(image, boxes):\n",
    "    im = np.array(image)\n",
    "    height, width = im.shape\n",
    "\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(im, cmap='gray')\n",
    "\n",
    "    for box1 in boxes:\n",
    "        box = box1[2:]\n",
    "        assert len(box) == 4, str(len(box))\n",
    "        upper_left_x = box[0] - box[2] / 2\n",
    "        upper_left_y = box[1] - box[3] / 2\n",
    "        rect = patches.Rectangle(\n",
    "            (upper_left_x * width, upper_left_y * height),\n",
    "            box[2] * width,\n",
    "            box[3] * height,\n",
    "            linewidth=1,\n",
    "            edgecolor=\"r\",\n",
    "            facecolor=\"none\",\n",
    "            label=box1[0],\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "    ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boardModel = BoardModel()\n",
    "boardModel.load_state_dict(torch.load('tictactoeBoard.pth', map_location='cpu'))\n",
    "boardModel.eval()\n",
    "\n",
    "fieldModel = FieldModel()\n",
    "fieldModel.load_state_dict(torch.load('tictactoeField.pth', map_location='cpu'))\n",
    "fieldModel.eval()\n",
    "print('Models loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('../data/boards/boardz/88.jpg')\n",
    "image = image.convert('L')\n",
    "imaget = to_tensor(image)\n",
    "out = boardModel(imaget.reshape(1, 1, 168, 168))\n",
    "bboxes = cellboxes_to_boxes(out)\n",
    "bboxes = non_max_suppression(bboxes[0], iou_threshold=0.5, threshold=0.4, box_format=\"midpoint\")\n",
    "\n",
    "fieldDict = {\n",
    "    '0': torch.zeros((1, 28, 28)),\n",
    "    '1': torch.zeros((1, 28, 28)),\n",
    "    '2': torch.zeros((1, 28, 28)),\n",
    "    '3': torch.zeros((1, 28, 28)),\n",
    "    '4': torch.zeros((1, 28, 28)),\n",
    "    '5': torch.zeros((1, 28, 28)),\n",
    "    '6': torch.zeros((1, 28, 28)),\n",
    "    '7': torch.zeros((1, 28, 28)),\n",
    "    '8': torch.zeros((1, 28, 28)),\n",
    "}\n",
    "\n",
    "confidenceDict = {\n",
    "    '0': 0,\n",
    "    '1': 0,\n",
    "    '2': 0,\n",
    "    '3': 0,\n",
    "    '4': 0,\n",
    "    '5': 0,\n",
    "    '6': 0,\n",
    "    '7': 0,\n",
    "    '8': 0,\n",
    "}\n",
    "\n",
    "for box in bboxes:\n",
    "    class_idx = box[0]\n",
    "    confidence = box[1]\n",
    "    if confidence > confidenceDict[str(int(class_idx))]:\n",
    "        x = box[2] * 168\n",
    "        y = box[3] * 168\n",
    "        w = box[4] * 168\n",
    "        h = box[5] * 168\n",
    "        im1 = image.crop(\n",
    "            (x - w / 2, y - h / 2, x + w / 2, y + h / 2)\n",
    "        )\n",
    "        im1 = im1.resize((28, 28))\n",
    "        fieldDict[str(int(class_idx))] = to_tensor(im1)\n",
    "\n",
    "fields = torch.stack(list(fieldDict.values()))\n",
    "\n",
    "out = fieldModel(fields)\n",
    "state = out.argmax(1).numpy().reshape(3, 3) - 1\n",
    "\n",
    "print(state)\n",
    "\n",
    "plot_image(imaget.cpu()[0].reshape(168, 168), bboxes)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2177f1ca12c1330a133c1d40b46100b268ab447cddcbdfdc0c7b2b7e4840e700"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
