# OutSmarted
![outSmarted](outsmarted.png)

### N√§chste Schritte
- Jesper: MiniMax mit Listen, BWKI-Bewerbung
- Simon: Server-Endpoint, C4 DQN
- Robert: Schach Alpha-Zero
- Anjo: C4 Datensatz

```
flutter run --release
```

- üêõ Die Kamera friert ein, sobald die App l√§nger im Hintergrund ist. (statelifecycle in Flutter)

### BW-KI
Titel: OutSmarted

Idee:
Wir bauen eine Smartphone-App, die √ºber die Kamera Brettspiele scannen kann. Sobald das Spiel selbst und sein State erkannt wurde, wird das die optimale Spielverhalten der Nutzer:in angezeigt. F√ºr das Frontend nutzen wir Flutter. Sobald mit dem CameraWidget ein Foto geschossen wurde, wird dieses direkt an unseren Backend-Server geschickt. Hier nutzen wir das Python-Framework Flask. Im ersten Schritt erkennt ein Klassifizierungsmodell das Spiel, um das es sich auf dem Bild handelt. F√ºr den Anfang sind die Klassen TicTacToe, Connect-Four & Chess. Basierend darauf gibt nun ein angepasstestes YOLO-object-detection-Modell, den State des Spieles auf dem Bild an. Der erhaltene State und die ausgew√§hlte Spieler:in wird dann genutzt, um den perfekten Zug zu berechnen. F√ºr TicTacToe nutzen wir daf√ºr den MiniMax-Algorithmus mit Alpha-Beta-Pruning, f√ºr Connect-Four ein erweitertes DQN und f√ºr Chess Alpha-Zero. Der State und der bestm√∂gliche Zug wird anschlie√üend im Frontend visualisiert.

Daten:
F√ºr die Klassifizierung des Spiels und vor allem die Erkennung des States √ºber object-detection brauchen wir hunderttausende annotierte Fotos. F√ºr TicTacToe haben wir bereits einen ausreichenden Datensatz mit handgezeichneten Spielen zum einen selbst erstellt und zum anderen von Kaggle. Essenziell ist hierbei das nachtr√§gliche Augmentieren √ºbers spiegeln, rotieren und vor allem das zuf√§llige Hinzuf√ºgen von Effekten wie die Ver√§nderung der Helligkeit oder der Farbe. Somit k√∂nnen wir unseren Datensatz vertausendfachen. F√ºr Connect-Four und Chess erstellen wir unsere Daten synthetisch √ºber ein Script in Blender. Nur so k√∂nnen wir die gro√üe Bandbreite an unterschiedlichen Spielbrettern und Hintergrundkontexten abdecken. Sollten wir unser Chess Reeinforcement-Learning Modell nicht komplett basierend auf Self-Play sondern unterst√ºtzt mit Moves auf Profi-Niveau trainieren, haben wir hierf√ºr bereits eine passende Datenbank gefunden. √Ñhnliches gilt auch f√ºr Connect-Four.
